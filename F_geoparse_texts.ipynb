{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geoparsing\n",
    "\n",
    "The last thing we want to do with our texts is to geoparse them. This involves two steps: extracting place names and resolving these to the structured geographic information. The [Mordecai](https://github.com/openeventdata/mordecai) library does this, with the help of some neural networks to resolve combined_place_df names to the correct combined_place_df based on the context. You will want to install mordecai in a separate virtual environment - make sure this environment is using the latest version of pip, to make sure tensorflow gets installed correctly. Some people have had issues running Mordecai on Macs - in case this is not working, the output of this file is included.\n",
    "\n",
    "First we will load the data and merge it with the predictions. We only want to run the parser on documents predicted to be relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10539, 16)\n",
      "(1344, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "      <th>seen</th>\n",
       "      <th>INCLUDE</th>\n",
       "      <th>12 - Coastal and marine Ecosystems</th>\n",
       "      <th>12 - Human and managed</th>\n",
       "      <th>12 - Mountains, snow and ice</th>\n",
       "      <th>12 - Rivers, lakes, and soil moisture</th>\n",
       "      <th>12 - Terrestrial ES</th>\n",
       "      <th>title_lcase</th>\n",
       "      <th>OA_id</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>authors</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408714.0</td>\n",
       "      <td>Significant climatic changes over northern Eur...</td>\n",
       "      <td>State of the ground: Climatology and changes d...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>stateofthegroundclimatologyandchangesduringthe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>546409.0</td>\n",
       "      <td>Grazing is a major land use in Australia's ran...</td>\n",
       "      <td>Climate change impacts on northern Australian ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>climatechangeimpactsonnorthernaustralianrangel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>603240.0</td>\n",
       "      <td>Global climate change is a major threat to bio...</td>\n",
       "      <td>Mechanistic models for the spatial spread of s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mechanisticmodelsforthespatialspreadofspeciesu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>96217.0</td>\n",
       "      <td>Instrumental observations suggest that Lake Ta...</td>\n",
       "      <td>Late-twentieth-century warming in Lake Tangany...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>latetwentiethcenturywarminginlaketanganyikaunp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2090016.0</td>\n",
       "      <td>The characteristic evolution of the synoptic-a...</td>\n",
       "      <td>Regional-scale weather patterns and wildland f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>regionalscaleweatherpatternsandwildlandfiresin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           abstract  \\\n",
       "3    408714.0  Significant climatic changes over northern Eur...   \n",
       "6    546409.0  Grazing is a major land use in Australia's ran...   \n",
       "8    603240.0  Global climate change is a major threat to bio...   \n",
       "10    96217.0  Instrumental observations suggest that Lake Ta...   \n",
       "11  2090016.0  The characteristic evolution of the synoptic-a...   \n",
       "\n",
       "                                                title  seen  INCLUDE  \\\n",
       "3   State of the ground: Climatology and changes d...   1.0      1.0   \n",
       "6   Climate change impacts on northern Australian ...   1.0      1.0   \n",
       "8   Mechanistic models for the spatial spread of s...   1.0      1.0   \n",
       "10  Late-twentieth-century warming in Lake Tangany...   1.0      1.0   \n",
       "11  Regional-scale weather patterns and wildland f...   1.0      1.0   \n",
       "\n",
       "    12 - Coastal and marine Ecosystems  12 - Human and managed  \\\n",
       "3                                  0.0                     0.0   \n",
       "6                                  0.0                     1.0   \n",
       "8                                  0.0                     0.0   \n",
       "10                                 0.0                     0.0   \n",
       "11                                 0.0                     0.0   \n",
       "\n",
       "    12 - Mountains, snow and ice  12 - Rivers, lakes, and soil moisture  \\\n",
       "3                            1.0                                    0.0   \n",
       "6                            0.0                                    0.0   \n",
       "8                            0.0                                    0.0   \n",
       "10                           0.0                                    1.0   \n",
       "11                           0.0                                    0.0   \n",
       "\n",
       "    12 - Terrestrial ES                                        title_lcase  \\\n",
       "3                   0.0  stateofthegroundclimatologyandchangesduringthe...   \n",
       "6                   1.0  climatechangeimpactsonnorthernaustralianrangel...   \n",
       "8                   1.0  mechanisticmodelsforthespatialspreadofspeciesu...   \n",
       "10                  0.0  latetwentiethcenturywarminginlaketanganyikaunp...   \n",
       "11                  1.0  regionalscaleweatherpatternsandwildlandfiresin...   \n",
       "\n",
       "   OA_id  doi  publication_year authors  prediction  \n",
       "3    NaN  NaN               NaN     NaN         NaN  \n",
       "6    NaN  NaN               NaN     NaN         NaN  \n",
       "8    NaN  NaN               NaN     NaN         NaN  \n",
       "10   NaN  NaN               NaN     NaN         NaN  \n",
       "11   NaN  NaN               NaN     NaN         NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "from D_run_cv_experiments import load_data\n",
    "\n",
    "df = load_data(False)\n",
    "df.loc[pd.isna(df[\"id\"]), \"id\"] = df.loc[pd.isna(df[\"id\"]), \"OA_id\"]\n",
    "df = df.merge(pd.read_csv('cv_data/INCLUDE/predictions_2_splits.csv'), how=\"outer\")\n",
    "print(df.shape)\n",
    "df = df[(df[\"INCLUDE\"]==1) | (df[\"prediction\"]>=0.5)]\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll also load any combined_place_df that have already been processed, or initialise an empty dataframe\n",
    "if os.path.exists(\"data/combined_place_df.csv\"):\n",
    "    processed_place_df = pd.read_csv(\"data/combined_place_df.csv\")\n",
    "    unprocessed_place_df = df[~df['id'].isin(processed_place_df)]\n",
    "else:\n",
    "    processed_place_df = pd.DataFrame()\n",
    "    unprocessed_place_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 17:32:19.514084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-03 17:32:19.514101: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models path: /home/max/software/mordecai-env/lib/python3.9/site-packages/mordecai/models/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 17:32:36.957995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-03 17:32:36.958016: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-03 17:32:36.958034: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (max-ThinkPad-X280): /proc/driver/nvidia/version does not exist\n",
      "2022-08-03 17:32:36.958720: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'word': 'Oxford',\n",
       "  'spans': [{'start': 17, 'end': 23}],\n",
       "  'country_predicted': 'GBR',\n",
       "  'country_conf': 0.95718795,\n",
       "  'geo': {'admin1': 'England',\n",
       "   'lat': '51.75222',\n",
       "   'lon': '-1.25596',\n",
       "   'country_code3': 'GBR',\n",
       "   'geonameid': '2640729',\n",
       "   'place_name': 'Oxford',\n",
       "   'feature_class': 'P',\n",
       "   'feature_code': 'PPLA2'}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we run the geoparser on a string, we get nice structured geographical information\n",
    "from mordecai import Geoparser\n",
    "geo = Geoparser()\n",
    "geo.geoparse(\"I travelled from Oxford to Ottawa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "places = []\n",
    "geos = []\n",
    "\n",
    "import re\n",
    "\n",
    "# Go through the rows of the dataframe\n",
    "for i, row in unprocessed_place_df.iterrows():\n",
    "    \n",
    "    # Get the text we want to geoparse, join title and abstract, get rid of copyright stuff\n",
    "    t = str(row['title']) + \" \" + str(row['abstract'])\n",
    "    t = t.split(\"Copyright (C)\")[0] \n",
    "    t = re.split(\"\\([C-c]\\) [1-2][0-9]{3} Elsevier\",t)[0] \n",
    "    t = t.split(\"Published by Elsevier\")[0] \n",
    "    t = t.split(\"Copyright. (C)\")[0] \n",
    "    t = re.split(\"\\. \\(C\\) [1-2][0-9]{3} \",t)[0] \n",
    "    t = re.split(\"\\. \\(C\\) Copyright\",t)[0]   \n",
    "    t = re.split(\"\\. \\\\xA9 [1-2][0-9]{3}\", t)[0] #Copyright symbol\n",
    "    \n",
    "    # Remove some common place names involved in environmental studies\n",
    "    t = re.sub(\"paris agreement\", \"\", t, flags=re.I)\n",
    "    t = re.sub(\"kyoto protocol\", \"\", t, flags=re.I)\n",
    "    t = re.sub(\"montreal protocol\", \"\", t, flags=re.I)\n",
    "    t = re.sub(\"london protocol\", \"\", t, flags=re.I)\n",
    "    \n",
    "    # geoparse\n",
    "    gp = geo.geoparse(t)\n",
    "    \n",
    "    # For each place, append to a list of dictionaries, with a field for the doc_id\n",
    "    for p in gp:\n",
    "        if \"geo\" in p:\n",
    "            for key, value in p[\"geo\"].items():\n",
    "                p[key] = value\n",
    "            del p[\"geo\"]\n",
    "            \n",
    "        p[\"doc_id\"] = row[\"id\"]\n",
    "        places.append(p)\n",
    "\n",
    "    # Save this every thousand rows, so we don't need to start again if we get interrupted\n",
    "    if i % 1000 == 0:\n",
    "        combined_place_df = processed_place_df.append(pd.DataFrame.from_dict(places))\n",
    "        print(combined_place_df.shape)\n",
    "        combined_place_df.to_csv(\"data/combined_place_df.csv\", index=False)\n",
    "    \n",
    "# Merge all the data together\n",
    "combined_place_df = processed_place_df.append(pd.DataFrame.from_dict(places))\n",
    "print(combined_place_df.shape)\n",
    "combined_place_df.to_csv(\"data/combined_place_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning geoparsing output\n",
    "\n",
    "The output from Mordecai has some common errors. Some of the ones we have identified are fixed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8916/3168564461.py:60: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Paris(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Paris)')) |\n",
      "/tmp/ipykernel_8916/3168564461.py:61: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Paris(?:\\S* ){0,15}Agreement)|(COP(?:\\S* ){0,15}Agreement)')) ,\n",
      "/tmp/ipykernel_8916/3168564461.py:68: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Copenhagen(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Copenhagen)')) |\n",
      "/tmp/ipykernel_8916/3168564461.py:69: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Copenhagen(?:\\S* ){0,3}Accord)|(Accord(?:\\S* ){0,3}Copenhagen)')) ,\n",
      "/tmp/ipykernel_8916/3168564461.py:76: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Berlin(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Berlin)')),\n",
      "/tmp/ipykernel_8916/3168564461.py:83: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Glasgow(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Glasgow)')),\n",
      "/tmp/ipykernel_8916/3168564461.py:90: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df['tstring'].str.contains('(Cancun(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Cancun)')) |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14659, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>spans</th>\n",
       "      <th>country_predicted</th>\n",
       "      <th>country_conf</th>\n",
       "      <th>admin1</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>country_code3</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>place_name</th>\n",
       "      <th>feature_class</th>\n",
       "      <th>feature_code</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>glacier lakes</td>\n",
       "      <td>[{'start': 843, 'end': 856}]</td>\n",
       "      <td>USA</td>\n",
       "      <td>0.956395</td>\n",
       "      <td>California</td>\n",
       "      <td>39.36129</td>\n",
       "      <td>-120.48243</td>\n",
       "      <td>USA</td>\n",
       "      <td>5352276</td>\n",
       "      <td>Glacier Lakes Trail</td>\n",
       "      <td>R</td>\n",
       "      <td>TRL</td>\n",
       "      <td>https://openalex.org/W2181980099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>-90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3523271</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>H</td>\n",
       "      <td>GULF</td>\n",
       "      <td>795562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>-90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3523271</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>H</td>\n",
       "      <td>GULF</td>\n",
       "      <td>1301456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>-90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3523271</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>H</td>\n",
       "      <td>GULF</td>\n",
       "      <td>795562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>-90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3523271</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>H</td>\n",
       "      <td>GULF</td>\n",
       "      <td>1301456.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word                         spans country_predicted  \\\n",
       "5342   glacier lakes  [{'start': 843, 'end': 856}]               USA   \n",
       "1606  Gulf of Mexico                           NaN               NaN   \n",
       "2100  Gulf of Mexico                           NaN               NaN   \n",
       "1606  Gulf of Mexico                           NaN               NaN   \n",
       "2100  Gulf of Mexico                           NaN               NaN   \n",
       "\n",
       "      country_conf      admin1       lat         lon country_code3 geonameid  \\\n",
       "5342      0.956395  California  39.36129  -120.48243           USA   5352276   \n",
       "1606      0.800000         NaN        25         -90           NaN   3523271   \n",
       "2100      0.800000         NaN        25         -90           NaN   3523271   \n",
       "1606      0.800000         NaN        25         -90           NaN   3523271   \n",
       "2100      0.800000         NaN        25         -90           NaN   3523271   \n",
       "\n",
       "               place_name feature_class feature_code  \\\n",
       "5342  Glacier Lakes Trail             R          TRL   \n",
       "1606       Gulf of Mexico             H         GULF   \n",
       "2100       Gulf of Mexico             H         GULF   \n",
       "1606       Gulf of Mexico             H         GULF   \n",
       "2100       Gulf of Mexico             H         GULF   \n",
       "\n",
       "                                doc_id  \n",
       "5342  https://openalex.org/W2181980099  \n",
       "1606                          795562.0  \n",
       "2100                         1301456.0  \n",
       "1606                          795562.0  \n",
       "2100                         1301456.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tstring'] = df['title'] + \" \" + df['abstract']\n",
    "\n",
    "gm_docs = df.loc[\n",
    "    (df['tstring'].str.lower().str.contains(\"gulf of mexico\")),\n",
    "    \"id\"\n",
    "]\n",
    "geocolumns = [\"word\", \"country_conf\", \"feature_code\",\"lat\",\"lon\",\"place_name\",\"feature_class\",\"geonameid\"]\n",
    "gm = pd.DataFrame({\"doc_id\": gm_docs})\n",
    "gm[geocolumns] = [\"Gulf of Mexico\",0.8,\"GULF\", 25, -90, \"Gulf of Mexico\", \"H\", 3523271]\n",
    "\n",
    "combined_place_df = pd.concat([combined_place_df, gm])\n",
    "\n",
    "\n",
    "lab_docs = df.loc[\n",
    "    (df['tstring'].str.lower().str.contains(\"labrador sea\")),\n",
    "    \"id\"\n",
    "]\n",
    "geocolumns = [\"word\", \"country_conf\", \"feature_code\",\"lat\",\"lon\",\"place_name\",\"feature_class\",\"geonameid\"]\n",
    "lab = pd.DataFrame({\"doc_id\": lab_docs})\n",
    "lab[geocolumns] = [\"Labrador Sea\",0.8,\"SEA\", 57, -55, \"Labrador Sea\", \"H\", 3424929]\n",
    "\n",
    "combined_place_df = pd.concat([combined_place_df, lab])\n",
    "\n",
    "baf_docs = df.loc[\n",
    "    (df['tstring'].str.lower().str.contains(\"baffin bay\")),\n",
    "    \"id\"\n",
    "]\n",
    "geocolumns = [\"word\", \"country_conf\", \"feature_code\",\"lat\",\"lon\",\"place_name\",\"feature_class\",\"geonameid\"]\n",
    "baf = pd.DataFrame({\"doc_id\": baf_docs})\n",
    "baf[geocolumns] = [\"Baffin Bay\",0.8,\"BAY\", 74, -68, \"Baffin Bay\", \"H\", 3831554]\n",
    "combined_place_df = pd.concat([combined_place_df, baf])\n",
    "\n",
    "\n",
    "ok_docs = df.loc[\n",
    "    (df['tstring'].str.lower().str.contains(\"sea of okhotsk\")) ,\n",
    "    \"id\"\n",
    "]\n",
    "geocolumns = [\"word\", \"country_conf\", \"feature_code\",\"lat\",\"lon\",\"place_name\",\"feature_class\",\"geonameid\"]\n",
    "ok = pd.DataFrame({\"doc_id\": ok_docs})\n",
    "ok[geocolumns] = [\"Sea of Okhotsk\",0.8, \"SEA\", 55, 150, \"Sea of Okhotsk\", \"H\", 2127380]\n",
    "combined_place_df = pd.concat([combined_place_df, ok])\n",
    "\n",
    "# Drop\n",
    "\n",
    "\n",
    "kyoto_docs = df.loc[\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto target\")) |\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto process\")) |\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto emission\")) |\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto gas\")) |\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto agreement\")) |\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto protocol\")) |\n",
    "    (df['tstring'].str.lower().str.contains(\"kyoto framework\")),\n",
    "    \"id\"\n",
    "]\n",
    "\n",
    "combined_place_df = combined_place_df.drop(combined_place_df[(combined_place_df['doc_id'].isin(kyoto_docs)) & (combined_place_df['word'].str.lower()==\"kyoto\")].index)\n",
    "\n",
    "paris_docs = df.loc[\n",
    "    (df['tstring'].str.contains('(Paris(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Paris)')) |\n",
    "    (df['tstring'].str.contains('(Paris(?:\\S* ){0,15}Agreement)|(COP(?:\\S* ){0,15}Agreement)')) ,\n",
    "    'id'\n",
    "]\n",
    "combined_place_df = combined_place_df.drop(combined_place_df[(combined_place_df['doc_id'].isin(paris_docs)) & (combined_place_df['word'].str.lower()==\"paris\")].index)\n",
    "\n",
    "# Copenhagen\n",
    "copenhagen_docs = df.loc[\n",
    "    (df['tstring'].str.contains('(Copenhagen(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Copenhagen)')) |\n",
    "    (df['tstring'].str.contains('(Copenhagen(?:\\S* ){0,3}Accord)|(Accord(?:\\S* ){0,3}Copenhagen)')) ,\n",
    "    'id'\n",
    "]\n",
    "combined_place_df = combined_place_df.drop(combined_place_df[(combined_place_df['doc_id'].isin(copenhagen_docs)) & (combined_place_df['word'].str.lower()==\"copenhagen\")].index)\n",
    "\n",
    "#Berlin\n",
    "berlin_docs = df.loc[\n",
    "    (df['tstring'].str.contains('(Berlin(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Berlin)')),\n",
    "    'id'\n",
    "]\n",
    "combined_place_df = combined_place_df.drop(combined_place_df[(combined_place_df['doc_id'].isin(berlin_docs)) & (combined_place_df['word'].str.lower()==\"berlin\")].index)\n",
    "\n",
    "#Glasgow\n",
    "berlin_docs = df.loc[\n",
    "    (df['tstring'].str.contains('(Glasgow(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Glasgow)')),\n",
    "    'id'\n",
    "]\n",
    "combined_place_df = combined_place_df.drop(combined_place_df[(combined_place_df['doc_id'].isin(berlin_docs)) & (combined_place_df['word'].str.lower()==\"berlin\")].index)\n",
    "\n",
    "#Cancun\n",
    "cancun_docs = df.loc[\n",
    "    (df['tstring'].str.contains('(Cancun(?:\\S* ){0,15}COP)|(COP(?:\\S* ){0,15}Cancun)')) |\n",
    "    (df['tstring'].str.lower().str.contains('cancun pledge')),\n",
    "    'id'\n",
    "]\n",
    "combined_place_df = combined_place_df.drop(combined_place_df[(combined_place_df['doc_id'].isin(cancun_docs)) & (combined_place_df['word'].str.lower()==\"cancun\")].index)\n",
    "\n",
    "\n",
    "geocolumns = [\"feature_code\", \"lat\", \"lon\", \"place_name\", \"feature_class\", \"geonameid\", \"country_code3\"]\n",
    "\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Pakistan\", geocolumns]=[\"PCLI\",30,70,\"Islamic Republic of Pakistan\",\"A\",1168579,\"PAK\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Colombia\", geocolumns]=[\"PCLI\",4,-73.25,\"Colombia\",\"A\",3686110, \"COL\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Argentina\", geocolumns]=[\"PCLI\",-34,-64,\"Argentine Republic\",\"A\",3865483, \"ARG\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Sahara\", geocolumns] = [\"DSRT\", 26, 13, \"Sahara\", \"T\", 2212709, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Alps\",geocolumns] = [\"MTS\", 46.41667, 10, \"Alps\", \"T\", 2661786, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Mediterranean Sea\",geocolumns] = [\"SEA\", 35, 20, \"Mediterranean Sea\", \"T\", 2661786, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"MEDITERRANEAN\",geocolumns] = [\"SEA\", 35, 20, \"Mediterranean Sea\", \"T\", 2661786, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"East China\",geocolumns] = [\"PCLI\", 35, 105, \"China\", \"A\", 1814991, \"CHN\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"South China\",geocolumns] = [\"PCLI\", 35, 105, \"China\", \"A\", 1814991, \"CHN\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Great Lakes\",geocolumns] = [\"LK\", 45.68751, -84.43753, \"Great Lakes\", \"H\", 4994594, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Catalonia\",geocolumns] = [\"ADM1\", 41.82046, 1.86768, \"Catalunya\", \"A\", 3336901, \"ESP\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"South Pacific\",geocolumns] = [\"OCN\", -45, -130, \"South Pacific Ocean\", \"H\", 4030483, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Gulf Coast\",geocolumns] = [\"AREA\", 29.36901, -95.00565, \"Gulf Coast\", \"L\", 7287689, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Gulf coast\",geocolumns] = [\"AREA\", 29.36901, -95.00565, \"Gulf Coast\", \"L\", 7287689, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Hainan Island\",geocolumns] = [\"ISL\", 19.2, 109.7, \"Hainan Dao\", \"T\", 1809055, \"CHN\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Red Sea\",geocolumns] = [\"SEA\", 20.26735, 38.53455, \"Red Sea\", \"H\", 350155, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Himalayan\",geocolumns] = [\"MTS\", 28,84, \"Himalayas\", \"T\", 1252558, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Himalayas\",geocolumns] = [\"MTS\", 28,84, \"Himalayas\", \"T\", 1252558, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"North America's\",geocolumns] = [\"CONT\", 46.07323, -100.54688, \"North America\", \"L\", 6255149, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Atlantic Ocean\",geocolumns] = [\"OCN\", 10, -25, \"Atlantic Ocean\", \"H\", 3373405, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Scandinavia\",geocolumns] = [\"RGN\", 63, 12, \"Scandinavia\", \"L\", 2614165, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"California (USA\",geocolumns] = [\"ADM1\", 37.25022, -119.75126, \"California\", \"A\", 5332921, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"California, USA\",geocolumns] = [\"ADM1\", 37.25022, -119.75126, \"California\", \"A\", 5332921, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"North Pacific\",geocolumns] = [\"OCN\", 30, -170, \"North Pacific Ocean\", \"H\", 4030875, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Huai\",geocolumns] = [\"STM\", 33.133333, 118.5, \"Huai He\", \"H\", 1807690, \"CHN\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Washington, DC\",geocolumns] = [\"PPLC\", 38.89511, -77.03637, \"Washington\", \"P\", 4140963, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Messinian\",geocolumns] = [\"ADM2\", 37.25, -21.83333, \"Nomos Messinias\", \"A\", 257149, \"GRC\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Ionian Sea\",geocolumns] = [\"SEA\", 39, 19, \"Ionian Sea\", \"H\", 2463713, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"NYC\",geocolumns] = [\"PPL\", 40.71427, -74.00597, \"New York City\", \"P\", 5128581, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Indian Ocean\",geocolumns] = [\"OCN\", -10, 70, \"Indian Ocean\", \"P\", 1545739, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"North Sea\",geocolumns] = [\"SEA\", 55, 3, \"North Sea\", \"P\", 2960848, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Philippine Sea\",geocolumns] = [\"SEA\", 20, 135, \"Philippine Sea\", \"P\", 1818190, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Black Sea\",geocolumns] = [\"SEA\", 43, 34, \"Black Sea\", \"H\", 630673, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Coral Sea\",geocolumns] = [\"SEA\", -20, 155, \"Coral Sea\", \"H\", 2194166, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Timor Sea\",geocolumns] = [\"SEA\", -11, 127, \"Timor Sea\", \"H\", 2078065, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Hudson Bay\",geocolumns] = [\"BAY\", 60, -85, \"Hudson Bay\", \"H\", 5978134, \"CAN\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Bering Sea\",geocolumns] = [\"SEA\", 60, -175, \"Bering Sea\", \"H\", 4031788, None]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Okhotsk Sea\",geocolumns] = [\"SEA\", 55, 150, \"Sea of Okhotsk\", \"H\", 2127380, None]\n",
    "\n",
    "combined_place_df.loc[combined_place_df[\"place_name\"]==\"Central Upper Nile\",geocolumns] = [\"ADM1\", 10, 32.7, \"Upper Nile\", \"A\", 381229, \"SSD\"]\n",
    "combined_place_df.loc[combined_place_df[\"place_name\"]==\"Gobolka Woqooyi Galbeed\",\"place_name\"] = \"Woqooyi Galbeed\"\n",
    "\n",
    "combined_place_df = combined_place_df[combined_place_df[\"place_name\"]!=\"Pacific County\"]\n",
    "combined_place_df = combined_place_df.loc[combined_place_df[\"word\"]!=\"B.V.\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"MMT\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Yellow\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Hadley\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Western North\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"colonies\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"TN\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"NH\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Mn\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Tx\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"TX\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Tn\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"FL\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Spartina\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Tamarix\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Eurasia\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Phillyrea\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"N-15\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"LT50\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"POSEIDON\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"LC50\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"El Nio\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"La Nia\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Red\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Gulf Stream\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"].str.len()>2]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"NH 1\"]\n",
    "combined_place_df = combined_place_df[combined_place_df[\"word\"]!=\"Quercus\"]\n",
    "\n",
    "\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"ZJP\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"MSW\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"CCS\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"Tier-3\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"N2O\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"VKT\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"OECD\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"States\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"North to South\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"Stabilising\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"Mass Railway\")]\n",
    "combined_place_df = combined_place_df[(combined_place_df[\"word\"]!=\"City\")]\n",
    "\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Ireland\", geocolumns]=[\"PCLI\",53,-8,\"Ireland\",\"A\",2963597,\"IRL\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"United States\", geocolumns] = [\"PCLI\",39.76,-98.5,\"United States\",\"A\",6252001, \"USA\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Czech Republic\", geocolumns] = [\"PCLI\",49.75,15,\"Czechia\",\"A\",3077311, \"CZE\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"Czechia\", geocolumns] = [\"PCLI\",49.75,15,\"Czechia\",\"A\",3077311, \"CZE\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"China\", geocolumns] = [\"PCLI\", 35, 105, \"China\", \"A\", 1814991, \"CHN\"]\n",
    "combined_place_df.loc[combined_place_df[\"word\"]==\"United Arab Emirates\", geocolumns] = [\"PCLI\", 23.75, 54.5, \"United Arab Emirates\", \"A\", 290557, \"ARE\"]\n",
    "\n",
    "\n",
    "# import pycountry_convert as pc\n",
    "# def get_cont(x):\n",
    "#     continents = {\n",
    "#         'NA': 'North America',\n",
    "#         'SA': 'South America', \n",
    "#         'AS': 'Asia',\n",
    "#         'OC': 'Oceania',\n",
    "#         'AF': 'Africa',\n",
    "#         'EU': 'Europe'\n",
    "#     }\n",
    "#     try:\n",
    "#         return continents[pc.country_alpha2_to_continent_code(pc.country_alpha3_to_country_alpha2(x))]\n",
    "#     except:\n",
    "#         return None\n",
    "\n",
    "\n",
    "# combined_place_df['continent'] = combined_place_df['country_code3'].apply(lambda x: get_cont(x))\n",
    "\n",
    "combined_place_df.to_csv('data/places.csv', index=False)\n",
    "\n",
    "print(combined_place_df.shape)\n",
    "\n",
    "combined_place_df.tail()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mordecai-env",
   "language": "python",
   "name": "mordecai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
